wandb:
  enable: true
  api_key: ???  # your wandb api key
  entity: ???  # the place to save your runs. can be your wandb username or team name
  project: ???  # the name of your project
  name: ???  # the name your rundata
train:
  epochs: 200
  dataloader:
    batch_size_per_gpu: 16
    selected_points: 1024  # points to be selected from every point cloud
    fps: true
    num_workers: 4  # the number of subprocess to load data
  lr: 1e-4
  lr_scheduler:
    which: cos_warmupLR
    stepLR:
      gamma: 0.2
      decay_step: 60
    cosLR:
      T_max: ${train.epochs}
      eta_min: 1e-8
    cos_warmupLR:
      warmup_epochs: 10  # number of epochs the warmup process takes
      warmup_init_lr: ${train.lr_scheduler.cos_warmupLR.eta_min}  # initial warmup lr
      T_max: 190  # number of epochs the cosine annealing process takes. should be epochs - warmup_epochs
      eta_min: 1e-8  # minimum lr of cosine annealing process
  optimizer:
    which: adamw  # adamw or sgd
    weight_decay: 1
  consistency_loss_factor: 0
  aux_loss:
    enable: false
    shared: false
    concat: true
    factor: 1
  validation_freq: 1
  ddp:
    which_gpu: [0]
    syn_bn: false  # synchronize batch normalization among gpus
    master_port: 14880  # please choose an available port
    nproc_this_node: 1  # how many gpu you want to use in current PC, should match 'which_gpu'
    world_size: 1 # this is equal to 'nproc_this_node' if you only use one PC

test:  # only valid when running the test script
  suffix:
    enable: false
    remark: just_try
  dataloader:
    batch_size_per_gpu: 2
    num_workers: 2  # ${test.ddp.nproc_this_node}  # the number of subprocess to load data
  ddp:
    which_gpu: [1]
    master_port: 12376  # please choose an available port
    nproc_this_node: 1  # how many gpu you want to use in current PC, should match 'which_gpu'
    world_size: 1  # this is equal to 'nproc_this_node' if you only use one PC
  visualize_preds:
    enable: false
    format: png  # png or ply
    vis_which: [0, 4, 7, 8, 15, 17, 19, 26]  # which category to be visualized
    num_vis: 100  # how many point clouds to visualize for one category
  visualize_downsampled_points:
    enable: true
    format: png  # png or ply
    vis_which: [0, 4, 7, 8, 15, 17, 19, 26]  # which category to be visualized
    num_vis: 100  # how many point clouds to visualize for one category
  visualize_attention_heatmap:
    enable: true
    format: png  # png or ply
    vis_which: [0, 4, 7, 8, 15, 17, 19, 26]  # which category to be visualized
    num_vis: 100  # how many point clouds to visualize for one category
    mode: one  # one, mode, compare
  visualize_combine:
    enable: true  
    vis_which: [sparse_col_sqr]
  few_points:
    enable: false
    num_points: 8
# the layer order inside the block is:
# embedding -> neighbor2point -> downsample -> neighbor2point -> downsample -> neighbor2point
#                             -> upsample -> neighbor2point -> upsample.-> neighbor2point
neighbor2point_block:
  enable: true
  STN: false
  res_link:
    enable: false
  embedding:
    K: [32, 32]
    group_type: [center_diff, center_diff]  # neighbor, diff, center_neighbor or center_diff
    conv1_in: [6, 128]
    conv1_out: [64, 64]
    conv2_in: [64, 64]
    conv2_out: [64, 64]
  downsample:
    ds_which: global_carve  # global or local or global_carve
    M: [512]
    asm: [dot]  # attention scoring method: dot, sub, add, dot-sub, l2, l2+, dot-neighbor
    bin:
      enable: [false]
      mode: [mode2] # mode1 or mode2
      num_bins: [8]
      sample_mode: [random] # topk or uniform or random
      norm_mode: [sigmoid] # minmax, sigmoid, tanh
    boltzmann:
      enable: [true]
      boltzmann_T: [0.05]
      norm_mode: [minmax] # minmax, z-score
    q_in: [128]
    q_out: [128]
    k_in: [128]
    k_out: [128]
    v_in: [128]
    v_out: [128]
    num_heads: [1]
    idx_mode: [sparse_col_sqr] 
    # local_std, col_sum, row_std, sparse_row_sum, sparse_row_std, sparse_col_sum, sparse_col_avg, sparse_col_sqr
  attention: # feature learning layers
    K: [32, 32]  # 3 values in the list means neighbor2point_block includes 3 neighbor2point layers. The 'K' for each layer is 40, 40 and 40 respectively
    attention_mode: [scalar_dot, scalar_dot] # scalar_dot, vector_sub
    group_type: [diff, diff]  # diff, neighbor, center_neighbor or center_diff
    q_in: [128, 128]
    q_out: [128, 128]
    k_in: [128, 128]
    k_out: [128, 128]
    v_in: [128, 128]
    v_out: [128, 128]
    num_heads: [4, 4]
    ff_conv1_channels_in: [128, 128]
    ff_conv1_channels_out: [512, 512]
    ff_conv2_channels_in: [512, 512]
    ff_conv2_channels_out: [128, 128]
